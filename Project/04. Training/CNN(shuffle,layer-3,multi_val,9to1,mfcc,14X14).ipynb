{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from random import shuffle\n",
    "\n",
    "TRAIN_DIR = 'test_train_image/all/9to1/mfcc_14/train'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "#print(train_folder_list)\n",
    "\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "train_input = []\n",
    "train_label = []\n",
    "\n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "#print(len(integer_encoded))\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded) #여기서 에러뜸\n",
    "#print(onehot_encoded)\n",
    "\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])\n",
    "        #trains.append(([np.array(img)],[np.array(onehot_encoded[index])]))\n",
    "        \n",
    "#random.shuffle(trains)\n",
    "train_tmp = [[x,y] for x,y in zip(train_input,train_label)]\n",
    "shuffle(train_tmp)\n",
    "train_input=[arr[0] for arr in train_tmp]\n",
    "train_label=[arr[1] for arr in train_tmp]\n",
    "\n",
    "'''\n",
    "for (i,j) in trains:\n",
    "    train_input.append(i)\n",
    "    train_label.append(j)\n",
    "'''\n",
    "train_input = np.reshape(train_input, (-1, 196))\n",
    "train_label = np.reshape(train_label, (-1, 8))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "\n",
    "#print(train_input)\n",
    "print(train_label)\n",
    "\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    "\n",
    "'''test data 설계'''\n",
    "\n",
    "TEST_DIR = 'test_train_image/all/9to1/mfcc_14/test'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    "        #tests.append(([np.array(img)],[np.array(onehot_encoded[index])]))\n",
    "\n",
    "#random.shuffle(tests)\n",
    "tests_tmp = [[x,y] for x,y in zip(test_input,test_label)]\n",
    "shuffle(tests_tmp)\n",
    "test_input=[arr[0] for arr in tests_tmp]\n",
    "test_label=[arr[1] for arr in tests_tmp]\n",
    "'''\n",
    "for (i,j) in tests:\n",
    "    test_input.append(i)\n",
    "    test_label.append(j)\n",
    "'''\n",
    "test_input = np.reshape(test_input, (-1, 196))\n",
    "test_label = np.reshape(test_label, (-1, 8))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "\n",
    "np.save(\"test_input.npy\",test_input)\n",
    "np.save(\"test_label.npy\",test_label)\n",
    "\n",
    "#print(test_input)\n",
    "print(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    " \n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 196])\n",
    "X_img = tf.reshape(X, [-1, 14, 14, 1])   # img 28x28x1 (black/white) #img 356x238x1\n",
    "Y = tf.placeholder(tf.float32, [None, 8])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,64],stddev =0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "tf.layers.batch_normalization(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "tf.layers.batch_normalization(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 128, 256], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "tf.layers.batch_normalization(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "L3_flat = tf.reshape(L3, [-1, 1024])\n",
    "W4 = tf.get_variable(\"W4\", shape=[1024, 8], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([8]))\n",
    "logits = tf.matmul(L3_flat, W4) + b\n",
    " \n",
    "# define cost/loss &amp;amp;amp; optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 200\n",
    " \n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(len(train_input) / batch_size)\n",
    " \n",
    "    for i in range(total_batch):\n",
    "        start = ((i + 1) * batch_size) - batch_size\n",
    "        end = ((i + 1) * batch_size)\n",
    "        batch_xs = train_input[start:end]\n",
    "        batch_ys = train_label[start:end]\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    " \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    " \n",
    "print('Learning Finished!')\n",
    " \n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: test_input, Y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
