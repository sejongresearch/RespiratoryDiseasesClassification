{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "from random import shuffle\n",
    "\n",
    "TRAIN_DIR = 'test_train_image/sc/mfcc_delta/train'\n",
    "train_folder_list = array(os.listdir(TRAIN_DIR))\n",
    "#print(train_folder_list)\n",
    "\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "train_input = []\n",
    "train_label = []\n",
    "\n",
    "label_encoder = LabelEncoder()  # LabelEncoder Class 호출\n",
    "integer_encoded = label_encoder.fit_transform(train_folder_list)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "#print(len(integer_encoded))\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded) #여기서 에러뜸\n",
    "#print(onehot_encoded)\n",
    "\n",
    "for index in range(len(train_folder_list)):\n",
    "    path = os.path.join(TRAIN_DIR, train_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        train_input.append([np.array(img)])\n",
    "        train_label.append([np.array(onehot_encoded[index])])\n",
    "        #trains.append(([np.array(img)],[np.array(onehot_encoded[index])]))\n",
    "        \n",
    "#random.shuffle(trains)\n",
    "train_tmp = [[x,y] for x,y in zip(train_input,train_label)]\n",
    "shuffle(train_tmp)\n",
    "train_input=[arr[0] for arr in train_tmp]\n",
    "train_label=[arr[1] for arr in train_tmp]\n",
    "\n",
    "'''\n",
    "for (i,j) in trains:\n",
    "    train_input.append(i)\n",
    "    train_label.append(j)\n",
    "'''\n",
    "train_input = np.reshape(train_input, (-1, 196))\n",
    "train_label = np.reshape(train_label, (-1, 2))\n",
    "train_input = np.array(train_input).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.float32)\n",
    "\n",
    "#print(train_input)\n",
    "#print(train_label)\n",
    "\n",
    "np.save(\"train_data.npy\", train_input)\n",
    "np.save(\"train_label.npy\", train_label)\n",
    "\n",
    "'''test data 설계'''\n",
    "\n",
    "TEST_DIR = 'test_train_image/sc/mfcc_delta/test'\n",
    "test_folder_list = array(os.listdir(TEST_DIR))\n",
    " \n",
    "test_input = []\n",
    "test_label = []\n",
    " \n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(test_folder_list)\n",
    " \n",
    "onehot_encoder = OneHotEncoder(sparse=False) \n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    " \n",
    "for index in range(len(test_folder_list)):\n",
    "    path = os.path.join(TEST_DIR, test_folder_list[index])\n",
    "    path = path + '/'\n",
    "    img_list = os.listdir(path)\n",
    "    for img in img_list:\n",
    "        img_path = os.path.join(path, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        test_input.append([np.array(img)])\n",
    "        test_label.append([np.array(onehot_encoded[index])])\n",
    "        #tests.append(([np.array(img)],[np.array(onehot_encoded[index])]))\n",
    "\n",
    "#random.shuffle(tests)\n",
    "tests_tmp = [[x,y] for x,y in zip(test_input,test_label)]\n",
    "shuffle(tests_tmp)\n",
    "test_input=[arr[0] for arr in tests_tmp]\n",
    "test_label=[arr[1] for arr in tests_tmp]\n",
    "'''\n",
    "for (i,j) in tests:\n",
    "    test_input.append(i)\n",
    "    test_label.append(j)\n",
    "'''\n",
    "test_input = np.reshape(test_input, (-1, 196))\n",
    "test_label = np.reshape(test_label, (-1, 2))\n",
    "test_input = np.array(test_input).astype(np.float32)\n",
    "test_label = np.array(test_label).astype(np.float32)\n",
    "\n",
    "np.save(\"test_input.npy\",test_input)\n",
    "np.save(\"test_label.npy\",test_label)\n",
    "\n",
    "#print(test_input)\n",
    "#print(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-18dfd2ca756b>:12: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-18dfd2ca756b>:52: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-18dfd2ca756b>:57: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    " \n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 196])\n",
    "X_img = tf.reshape(X, [-1, 14, 14, 1])   # img 28x28x1 (black/white) #img 356x238x1\n",
    "Y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32],stddev =0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "tf.layers.batch_normalization(L1)\n",
    "#L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "tf.layers.batch_normalization(L2)\n",
    "#L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "tf.layers.batch_normalization(L3)\n",
    "#L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([3, 3, 128, 256], stddev=0.01))\n",
    "L4 = tf.nn.conv2d(L3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L4 = tf.nn.relu(L4)\n",
    "tf.layers.batch_normalization(L4)\n",
    "L4 = tf.nn.max_pool(L4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "L4_flat = tf.reshape(L4, [-1, 7 * 7 * 256])\n",
    "\n",
    "W5 = tf.get_variable('W5',shape=[7*7*256 ,4096],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([4096]))\n",
    "L5 = tf.matmul(L4_flat,W5)+b5\n",
    "L5 = tf.nn.relu(L5)\n",
    "tf.layers.batch_normalization(L5)\n",
    "\n",
    "W6 = tf.get_variable('W6',shape=[4096,1000],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b6 = tf.Variable(tf.random_normal([1000]))\n",
    "L6 = tf.matmul(L5,W6)+b6\n",
    "L6 = tf.nn.relu(L6)\n",
    "tf.layers.batch_normalization(L6)\n",
    "\n",
    "W7 = tf.get_variable('W7',shape=[1000,2],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b7 = tf.Variable(tf.random_normal([2]))\n",
    "L7 = tf.matmul(L6,W7)+b7\n",
    "\n",
    "logits = tf.layers.dense(inputs=L7, units=2)\n",
    "\n",
    " \n",
    "# define cost/loss &amp;amp;amp; optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 13.923553586\n",
      "Epoch: 0002 cost = 2.167604792\n",
      "Epoch: 0003 cost = 1.165641677\n",
      "Epoch: 0004 cost = 0.515062082\n",
      "Epoch: 0005 cost = 0.507968485\n",
      "Epoch: 0006 cost = 0.510304299\n",
      "Epoch: 0007 cost = 0.479097831\n",
      "Epoch: 0008 cost = 0.438293362\n",
      "Epoch: 0009 cost = 0.462444758\n",
      "Epoch: 0010 cost = 0.446990192\n",
      "Epoch: 0011 cost = 0.446227098\n",
      "Epoch: 0012 cost = 0.452171445\n",
      "Epoch: 0013 cost = 0.443354666\n",
      "Epoch: 0014 cost = 0.447389001\n",
      "Epoch: 0015 cost = 0.447575563\n",
      "Learning Finished!\n",
      "Accuracy: 0.7027027\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 30\n",
    " \n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    " \n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(len(train_input) / batch_size)\n",
    " \n",
    "    for i in range(total_batch):\n",
    "        start = ((i + 1) * batch_size) - batch_size\n",
    "        end = ((i + 1) * batch_size)\n",
    "        batch_xs = train_input[start:end]\n",
    "        batch_ys = train_label[start:end]\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    " \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    " \n",
    "print('Learning Finished!')\n",
    " \n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: test_input, Y: test_label}))\n",
    "\n",
    "#learning_rate 0.03 >0.83 나오는데 불안정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
